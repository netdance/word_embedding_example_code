{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68bbf0e8-944b-461e-af72-a5a11212b16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/jdriscoll/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jdriscoll/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04656ab1-1edb-4dff-a18c-02bc08e9282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence']\n",
      "['pilot']\n",
      "['scene', 'one']\n",
      "['title', 'the', 'year', '2030']\n",
      "['narrator', 'kids', 'i', \"'m\", 'going', 'to', 'tell', 'you', 'an', 'incredible', 'story', 'the', 'story', 'of', 'how', 'i', 'met', 'your', 'mother']\n",
      "['son', 'are', 'we', 'being', 'punished', 'for', 'something']\n",
      "['narrator', 'no']\n",
      "['daughter', 'yeah', 'is', 'this', 'going', 'to', 'take', 'a', 'while']\n",
      "['narrator', 'yes', 'kids', 'are', 'annoyed', 'twenty-five', 'years', 'ago', 'before', 'i', 'was', 'dad', 'i', 'had', 'this', 'whole', 'other', 'life']\n",
      "['music', 'plays', 'title', '``', 'how', 'i', 'met', 'your', 'mother', \"''\", 'appears']\n",
      "['narrator', 'it', 'was', 'way', 'back', 'in', '2005.', 'i', 'was', 'twenty-seven', 'just', 'starting', 'to', 'make', 'it', 'as', 'an', 'architect', 'and', 'living', 'in', 'new', 'york', 'with', 'my', 'friend', 'marshall', 'my', 'best', 'friend', 'from', 'college', 'my', 'life', 'was', 'good', 'and', 'then', 'uncle', 'marshall', 'went', 'and', 'screwed', 'the', 'whole', 'thing', 'up']\n",
      "['marshall', 'opens', 'ring', 'will', 'you', 'marry', 'me']\n",
      "['ted', 'yes', 'perfect', 'and', 'then', 'you', \"'re\", 'engaged', 'you', 'pop', 'the', 'champagne', 'you', 'drink', 'a', 'toast', 'you', 'have', 's', 'x', 'on', 'the', 'kitchen', 'floor', '...', 'do', \"n't\", 'have', 's', 'x', 'on', 'our', 'kitchen', 'floor']\n",
      "['marshall', 'got', 'it', 'thanks', 'for', 'helping', 'me', 'plan', 'this', 'out', 'ted']\n",
      "['ted', 'dude', 'are', 'you', 'kidding', 'it', \"'s\", 'you', 'and', 'lily', 'i', \"'ve\", 'been', 'there', 'for', 'all', 'the', 'big', 'moments', 'of', 'you', 'and', 'lily', 'the', 'night', 'you', 'met', 'your', 'first', 'date', '...', 'other', 'first', 'things']\n",
      "['marshall', 'laughs', 'yeah', 'sorry', 'we', 'thought', 'you', 'were', 'asleep']\n",
      "['ted', 'it', \"'s\", 'physics', 'marshall', 'if', 'the', 'bottom', 'bunk', 'moves', 'the', 'top', 'bunk', 'moves', 'too', 'my', 'god', 'you', \"'re\", 'getting', 'engaged', 'tonight']\n",
      "['marshall', 'yeah', 'what', 'are', 'you', 'doing', 'tonight']\n",
      "['scene', 'freezes']\n",
      "['narrator', 'what', 'was', 'i', 'doing', 'your', 'uncle', 'marshall', 'was', 'taking', 'the', 'biggest', 'step', 'of', 'his', 'life', 'and', 'me-i', \"'m\", 'calling', 'your', 'uncle', 'barney']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import string\n",
    "from gensim.models import Phrases\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sentences = []\n",
    "bigram = Phrases()\n",
    "with open(\"corpus/sentences.csv\", \"r\") as sentencesfile:\n",
    "    reader = csv.reader(sentencesfile, delimiter = \",\")\n",
    "    count = 0\n",
    "    for row in reader:\n",
    "        count += 1\n",
    "        sentence = [\n",
    "            word for word in nltk.word_tokenize(row[4].lower())\n",
    "            if word not in string.punctuation\n",
    "        ]\n",
    "        if count <= 20: \n",
    "            print(sentence)\n",
    "        sentences.append(sentence)\n",
    "        bigram.add_vocab([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e95c371e-b8a7-4f7c-a4a2-e2b9b24e392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_'m                 4607\n",
      "it_'s                4288\n",
      "you_'re              2660\n",
      "do_n't               2460\n",
      "that_'s              2044\n",
      "in_the               1696\n",
      "gon_na               1576\n",
      "you_know             1509\n",
      "i_do                 1498\n",
      "this_is              1408\n",
      "and_i                1390\n",
      "want_to              1073\n",
      "it_was               1060\n",
      "on_the               1056\n",
      "at_the               1035\n",
      "ca_n't               1034\n",
      "we_'re               1033\n",
      "i_was                1020\n",
      "of_the               1014\n",
      "are_you              999\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "bigram_counter = Counter()\n",
    "for key in bigram.vocab.keys():\n",
    "    if key not in stopwords.words(\"english\"):\n",
    "        if len(key.split(\"_\")) > 1:\n",
    "            bigram_counter[key] += bigram.vocab[key]\n",
    "\n",
    "for key, counts in bigram_counter.most_common(20):\n",
    "    print('{0: <20} {1}'.format(key, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68012ea0-52d9-4f5d-a75f-60d9fcec08c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do_n't               2460\n",
      "gon_na               1576\n",
      "ca_n't               1034\n",
      "did_n't              719\n",
      "come_on              587\n",
      "end_of               472\n",
      "'m_sorry             453\n",
      "my_god               442\n",
      "kind_of              398\n",
      "from_2030            394\n",
      "all_right            354\n",
      "they_'re             351\n",
      "does_n't             347\n",
      "end_flashback        328\n",
      "of_course            322\n",
      "right_now            314\n",
      "'ve_been             303\n",
      "new_york             300\n",
      "a_lot                297\n",
      "look_at              265\n",
      "trying_to            238\n",
      "a_few                196\n",
      "'ve_got              190\n",
      "my_life              185\n",
      "so_much              183\n",
      "wo_n't               179\n",
      "each_other           178\n",
      "got_ta               168\n",
      "talking_about        159\n",
      "what_happened        157\n",
      "talk_about           154\n",
      "last_night           144\n",
      "at_least             141\n",
      "excuse_me            138\n",
      "s_x                  131\n",
      "wan_na               130\n",
      "my_dad               126\n",
      "supposed_to          126\n",
      "get_married          121\n",
      "more_than            119\n",
      "met_your             116\n",
      "phone_rings          111\n",
      "part_of              109\n",
      "looks_like           109\n",
      "best_friend          105\n",
      "barney_stinson       104\n",
      "said_``              101\n",
      "in_fact              100\n",
      "mr_druthers          100\n",
      "in_front             99\n"
     ]
    }
   ],
   "source": [
    "bigram_model = Word2Vec(sentences=bigram[sentences], vector_size=300)\n",
    "bigram_model_counter = Counter()\n",
    "for key in bigram_model.wv.index_to_key:\n",
    "    if key not in stopwords.words(\"english\"):\n",
    "        if len(key.split(\"_\")) > 1:\n",
    "            bigram_model_counter[key] += bigram_model.wv.get_vecattr(key, \"count\")\n",
    "\n",
    "for key, counts in bigram_model_counter.most_common(50):\n",
    "    print('{0: <20} {1}'.format(key, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6749c54e-aa9f-4224-99e2-95b623586020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barney', 0.8083707690238953),\n",
       " ('robin', 0.807981550693512),\n",
       " ('zoey', 0.7670478224754333),\n",
       " ('victoria', 0.7506242394447327),\n",
       " ('stella', 0.7298815846443176),\n",
       " ('james', 0.6880024671554565),\n",
       " ('nora', 0.6795037984848022),\n",
       " ('honey', 0.653923511505127),\n",
       " ('brad', 0.6511144638061523),\n",
       " ('don', 0.649530827999115)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model.wv.most_similar(positive=['marshall', 'lily'], negative=['ted'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d56ab6d5-e0ae-47cb-a886-e03ef7f90d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('freaking_out', 0.9337726831436157),\n",
       " ('having_trouble', 0.932257890701294),\n",
       " ('killing_me', 0.9291092753410339),\n",
       " ('distracted', 0.9287639856338501),\n",
       " ('sick', 0.9272034764289856),\n",
       " ('hungry', 0.9259573817253113),\n",
       " ('smiling', 0.9251943826675415),\n",
       " ('so_excited', 0.9243179559707642),\n",
       " ('outta_here', 0.920470654964447),\n",
       " ('an_idiot', 0.9185579419136047)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model.wv.most_similar(positive=['getting_married'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10cc343b-0a2d-43e6-98fd-d566b4b46c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('city', 0.8571550846099854),\n",
       " ('town', 0.8310223817825317),\n",
       " ('side', 0.8275214433670044),\n",
       " ('statue', 0.818712055683136),\n",
       " ('our_lives', 0.8137703537940979),\n",
       " ('stranded', 0.8110111355781555),\n",
       " ('masters', 0.8105744123458862),\n",
       " ('backyard', 0.8094143271446228),\n",
       " ('premiere', 0.8087864518165588),\n",
       " ('its', 0.8073733448982239)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model.wv.most_similar([\"new_york\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47b66a22-8f5f-4e00-8f3a-9dc3afece9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('robin', 0.9670109748840332),\n",
       " ('lily', 0.8783924579620361),\n",
       " ('marshall', 0.8722664713859558),\n",
       " ('ted', 0.872049868106842),\n",
       " ('victoria', 0.818345844745636),\n",
       " ('zoey', 0.8106648325920105),\n",
       " ('stella', 0.7715747356414795),\n",
       " ('nora', 0.751941442489624),\n",
       " ('james', 0.7066298723220825),\n",
       " ('randy', 0.6985768675804138),\n",
       " ('brad', 0.6928389072418213),\n",
       " ('arthur', 0.6884772181510925),\n",
       " ('totally', 0.6809297800064087),\n",
       " ('don', 0.6700106263160706),\n",
       " ('uh', 0.6690816283226013),\n",
       " ('jerry', 0.6676561236381531),\n",
       " ('claudia', 0.6590033769607544),\n",
       " ('honey', 0.6483128666877747),\n",
       " ('jen', 0.6412301063537598),\n",
       " ('carl', 0.6295939683914185)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model.wv.most_similar(positive=['barney'], topn=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
